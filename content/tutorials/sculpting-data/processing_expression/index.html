---
title: "Processing Expression"
layout: "tutorial"
---

<p>Up to this point, you’ve learned how audio flows:</p>

<ul>
  <li>containers feed buffers</li>
  <li>buffers run processors</li>
  <li>processors shape data.</li>
</ul>

<p>
  Now we expand the vocabulary of processors themselves. In MayaFlux,
  mathematics, logic, feedback, and generation are not side features, they are
  first-class sculpting tools. This tutorial explores how computational
  expressions become sound-shaping primitives.
</p>

<p>
  <em>
    In MayaFlux, polynomials don't calculate—they sculpt. Logic doesn't
    branch—it decides. This tutorial shows you how mathematical expressions
    become sonic transformations.
  </em>
</p>

<hr />

<!-- =======================  TUTORIAL SECTION ======================= -->

<section class="tutorial-section">
  <div class="tutorial-row">
    <div class="tutorial-card" data-target="poly-expanded">
      <h3 class="tutorial-title">Tutorial: Polynomial Waveshaping</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Simplest Path</h4>

      <p>Run this code. Your file plays with harmonic distortion.</p>

      <pre><code class="language-cpp">
void compose() {
    auto sound = vega.read_audio("path/to/file.wav") | Audio;
    auto buffers = MayaFlux::get_last_created_container_buffers();

    // Polynomial: x² generates harmonics
    auto poly = vega.Polynomial([](double x) { return x * x; });
    auto processor = MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffers[0], poly);
}
            </code></pre>

      <p>Replace <code>"path/to/file.wav"</code> with an actual path.</p>

      <p>
        The audio sounds richer, warmer—subtle saturation. That's harmonic
        content added by the squaring function.
      </p>
    </div>
  </div>
</section>

<!-- =======================  EXPANDED SECTION ======================= -->

<section id="poly-expanded" class="tutorial-expanded">
  <h2>Expansion 1: Why Polynomials Shape Sound</h2>

  <details>
    <summary>Click to expand: Transfer Functions as Geometry</summary>

    <p>
      When you write <code>x * x</code>, you're not "squaring numbers." You're
      defining a <strong>transfer curve</strong>:
    </p>

    <ul>
      <li>Input -1.0 → Output 1.0</li>
      <li>Input 0.5 → Output 0.25 (quieter)</li>
      <li>Input 1.0 → Output 1.0 (same)</li>
    </ul>

    <p>
      This asymmetry adds harmonics. The waveform's shape
      <strong>bends</strong>—its geometry changes.
    </p>

    <p>
      Analog distortion (tubes, tape) works this way: input voltage doesn't map
      linearly to output. The circuit's response curve adds character.
    </p>

    <p>
      Polynomials let you design that curve digitally.
      <code>x * x</code> is gentle. <code>x * x * x</code> adds different
      harmonics (odd instead of even). <code>std::tanh(x)</code> mimics tube
      saturation.
    </p>

    <p>You're sculpting frequency response through function shape.</p>
  </details>

  <h2>Expansion 2: What <code>vega.Polynomial()</code> Creates</h2>

  <details>
    <summary>Click to expand: Nodes vs. Processors</summary>

    <p>
      <code>vega.Polynomial([](double x) { return x * x; })</code>
      creates a <strong>Polynomial node</strong>—a mathematical expression that
      processes one sample at a time.
    </p>

    <p>
      By itself, the node doesn't touch your audio. You wrap it in a
      <strong>PolynomialProcessor</strong>:
    </p>

    <pre><code class="language-cpp">
auto processor = MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffers[0], poly);
        </code></pre>

    <p><strong>Why this separation?</strong></p>

    <ul>
      <li>
        <strong>Node</strong>: The math itself—reusable, chainable, inspectable
      </li>
      <li>
        <strong>Processor</strong>: The attachment mechanism—knows
        <em>how</em> to apply the node to a buffer
      </li>
    </ul>

    <p>
      Same node, different processors → different results. You'll see this
      pattern everywhere in MayaFlux.
    </p>

    <p>
      The node is the <em>idea</em>. The processor is the <em>application</em>.
    </p>
  </details>

  <h2>Expansion 3: PolynomialMode::DIRECT</h2>

  <details>
    <summary>Click to expand: Three Processing Modes</summary>

    <p>Polynomials have three modes:</p>

    <ul>
      <li>
        <strong>DIRECT</strong>: <code>f(x)</code> where x is the current sample
      </li>
      <li>
        <strong>RECURSIVE</strong>: <code>f(y[n-1], y[n-2], ...)</code> where
        output depends on previous outputs
      </li>
      <li>
        <strong>FEEDFORWARD</strong>: <code>f(x[n], x[n-1], ...)</code> where
        output depends on input history
      </li>
    </ul>

    <p>
      Right now you're using DIRECT mode—each sample transformed independently.
      This is <strong>memoryless</strong> waveshaping.
    </p>

    <p>
      Later sections explore time-aware modes. RECURSIVE creates filters and
      feedback. FEEDFORWARD creates delay-based effects.
    </p>

    <p>For now: DIRECT mode = instant transformation. No memory. No delay.</p>
  </details>

  <h2>Expansion 4: What <code>create_processor()</code> Does</h2>

  <details>
    <summary>Click to expand: Attaching to Buffers</summary>

    <p>When you call:</p>

    <pre><code class="language-cpp">
auto processor = MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffers[0], poly);
        </code></pre>

    <p>MayaFlux does this:</p>

    <ol>
      <li>
        Creates a <code>PolynomialProcessor</code> wrapping your polynomial node
      </li>
      <li>Gets <code>buffers[0]</code>'s processing chain</li>
      <li>Adds the processor to that chain</li>
      <li>Returns the processor handle</li>
    </ol>

    <p>The buffer now runs your polynomial on every cycle:</p>

    <ul>
      <li>512 samples arrive from the Container</li>
      <li>Your polynomial processes each sample: <code>y = x * x</code></li>
      <li>Transformed samples continue to speakers</li>
    </ul>

    <p>
      The processor is now part of the buffer's flow. It runs automatically
      every cycle until removed.
    </p>
  </details>

  <hr />

  <h2>Try It</h2>

  <pre><code class="language-cpp">
// Cubic distortion (more aggressive, odd harmonics)
auto poly = vega.Polynomial([](double x) { return x * x * x; });

// Chebyshev waveshaping (precise harmonic control)
auto poly = vega.Polynomial([](double x) { return 2*x*x - 1; });

// Soft clipping (analog-style limiting)
auto poly = vega.Polynomial([](double x) {
    return x / (1.0 + std::abs(x));
});

// Extreme fold-back distortion
auto poly = vega.Polynomial([](double x) {
    return std::sin(x * 5.0);
});
    </code></pre>

  <p>
    Listen to each. Same structure, different curves. Each curve generates
    different harmonic content.
  </p>

  <p>
    You're not "processing audio"—you're
    <strong>sculpting the transfer function</strong>.
  </p>
</section>


<hr />

<!-- =======================  TUTORIAL SECTION ======================= -->

<section class="tutorial-section">

    <div class="tutorial-row">

        <div class="tutorial-card" data-target="recursive-expanded">
            <h3 class="tutorial-title">Tutorial: Recursive Polynomials (Filters and Feedback)</h3>
            <p class="hint">Click this card to reveal full explanation</p>

            <h4>The Next Step</h4>

            <p>You have memoryless waveshaping. Now add memory.</p>

            <pre><code class="language-cpp">
void compose() {
    auto sound = vega.read_audio("path/to/file.wav") | Audio;
    auto buffers = MayaFlux::get_last_created_container_buffers();

    // Recursive: output depends on previous outputs
    auto recursive = vega.Polynomial(
        [](std::span<double> history) {
            // history[0] = previous output, history[1] = two samples ago
            return 0.5 * history[0] + 0.3 * history[1];
        },
        PolynomialMode::RECURSIVE,
        2  // remember 2 previous outputs
    );

    auto processor = MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffers[0], recursive);
}
            </code></pre>

            <p>
            Run this. You hear echo/resonance—the signal feeds back into itself.
            </p>
        </div>

    </div>

</section>

<!-- =======================  EXPANDED SECTION ======================= -->

<section id="recursive-expanded" class="tutorial-expanded">

    <h2>Expansion 1: Why This Is a Filter</h2>

    <details>
        <summary>Click to expand: IIR Filters Are Recursive Polynomials</summary>

        <p>Classic IIR filter equation:</p>

        <pre><code class="language-text">
y[n] = b0*x[n] + a1*y[n-1] + a2*y[n-2]
        </code></pre>

        <p>
        Your recursive polynomial <strong>is</strong> that filter—just written as a lambda:
        </p>

        <pre><code class="language-cpp">
[](std::span<double> history) {
    return 0.5 * history[0] + 0.3 * history[1];
}
        </code></pre>

        <p>
        Difference: You can write <strong>nonlinear</strong> feedback:
        </p>

        <pre><code class="language-cpp">
[](std::span<double> history) {
    return history[0] * std::sin(history[1]);  // nonlinear!
}
        </code></pre>

        <p>
        Traditional DSP libraries can't do this. Fixed coefficients only.
        </p>

        <p>
        Polynomials let you design arbitrary recursive functions—not just linear filters.
        </p>

    </details>

    <h2>Expansion 2: The History Buffer</h2>

    <details>
        <summary>Click to expand: How RECURSIVE Mode Works</summary>

        <p>When you write:</p>

        <pre><code class="language-cpp">
PolynomialMode::RECURSIVE, 2
        </code></pre>

        <p>
        The polynomial maintains a buffer of <strong>previous outputs</strong>:
        </p>

        <pre><code class="language-text">
history[0] = y[n-1]  (last output)
history[1] = y[n-2]  (two samples ago)
        </code></pre>

        <p>Each cycle:</p>

        <ol>
            <li>Your lambda reads from <code>history</code></li>
            <li>Computes new output</li>
            <li>Polynomial pushes output into <code>history</code> (shifts everything down)</li>
            <li>Loop repeats</li>
        </ol>

        <p>
        The buffer size determines how far back you can look.
        Larger buffers = longer memory.
        </p>

        <p>For a 100-sample buffer at 48 kHz:</p>

        <pre><code class="language-text">
100 samples ÷ 48000 Hz ≈ 2 ms of history
        </code></pre>

        <p>
        This is how you build delays, reverbs, resonant filters—anything that needs temporal memory.
        </p>

    </details>

    <h2>Expansion 3: Stability Warning</h2>

    <details>
        <summary>Click to expand: Recursive Systems Can Explode</summary>

        <p>
        <strong>Critical rule</strong>: Keep feedback coefficients summing to &lt; 1.0 for guaranteed stability.
        </p>

        <p><strong>Safe:</strong></p>

        <pre><code class="language-cpp">
return 0.6*history[0] + 0.3*history[1];  // sum = 0.9 < 1.0
        </code></pre>

        <p><strong>Dangerous:</strong></p>

        <pre><code class="language-cpp">
return 1.2*history[0];  // WILL EXPLODE (unbounded growth)
        </code></pre>

        <p>
        Why? Each cycle multiplies previous output by 1.2.
        Exponential growth. Your speakers won't thank you.
        </p>

        <p>
        MayaFlux won't stop you—this is a creative tool, not a safety guard.
        Instability can be interesting (briefly).
        Controlled feedback explosion creates chaotic textures.
        </p>

        <p>
        But for stable filters: keep gain &lt; 1.0.
        </p>

    </details>

    <h2>Expansion 4: Initial Conditions</h2>

    <details>
        <summary>Click to expand: Seeding the History Buffer</summary>

        <p>
        Recursive polynomials need starting values.
        Default: <code>[0.0, 0.0, ...]</code>
        </p>

        <p>You can seed them:</p>

        <pre><code class="language-cpp">
recursive->set_initial_conditions({0.5, -0.3, 0.1});
        </code></pre>

        <p><strong>Why?</strong></p>

        <ol>
            <li>
                <strong>Impulse responses</strong>:
                Inject energy without external input.
                The filter "pings" on its own.
            </li>
            <li>
                <strong>Self-oscillation</strong>:
                Non-zero initial conditions + feedback gain ≥ 1.0 = continuous tone.
            </li>
            <li>
                <strong>Warm start</strong>:
                Resume from previous state instead of cold-starting at zero.
            </li>
        </ol>

        <p>Example (resonant ping):</p>

        <pre><code class="language-cpp">
auto resonator = vega.Polynomial(
    [](std::span<double> history) {
        return 0.99 * history[0] - 0.5 * history[1];
    },
    PolynomialMode::RECURSIVE,
    2
);
resonator->set_initial_conditions({1.0, 0.0});  // kick-start the resonance
        </code></pre>

    </details>

    <hr>

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Karplus-Strong string synthesis (plucked string)
auto string = vega.Polynomial(
    [](std::span<double> history) {
        return 0.996 * (history[0] + history[1]) / 2.0;  // lowpass + feedback
    },
    PolynomialMode::RECURSIVE,
    100  // ~480 Hz at 48kHz
);
string->set_initial_conditions(
    std::vector<double>(100, vega.Random(-1.0, 1.0))
);  // noise burst

// Nonlinear resonator (saturating feedback)
auto nonlinear = vega.Polynomial(
    [](std::span<double> history) {
        double fb = 0.8 * history[0];
        return std::tanh(fb * 3.0);  // soft saturation in loop
    },
    PolynomialMode::RECURSIVE,
    1
);

// Comb filter (delay-based coloration)
auto comb = vega.Polynomial(
    [](std::span<double> history) {
        return history[0] + 0.5 * history[50];  // 50-sample delay
    },
    PolynomialMode::RECURSIVE,
    50
);
    </code></pre>

</section>

<hr />

<!-- =======================  TUTORIAL SECTION ======================= -->

<section class="tutorial-section">

    <div class="tutorial-row">

        <div class="tutorial-card" data-target="logic-expanded">
            <h3 class="tutorial-title">Tutorial: Logic as Decision Maker</h3>
            <p class="hint">Click this card to reveal full explanation</p>

            <h4>The Simplest Path</h4>

            <p>Run this code. You'll hear rhythmic pulses.</p>

            <pre><code class="language-cpp">
void compose() {
    auto buffer = vega.AudioBuffer()[0] | Audio;

    // Logic node: threshold detection
    auto logic = vega.Logic(LogicOperator::THRESHOLD, 0.0);

    auto processor = MayaFlux::create_processor&lt;LogicProcessor&gt;(
        buffer,
        logic
    );

    processor->set_modulation_type(LogicProcessor::ModulationType::REPLACE);

    // Feed a sine wave into the logic node
    auto sine = vega.Sine(2.0);
    logic->set_input_node(sine);
}
            </code></pre>

            <p>
            What you hear: 2 Hz pulse train—beeps every half second.
            </p>

            <p>
            The sine wave crosses zero twice per cycle.
            Logic detects the crossings.
            Output becomes binary: 1.0 (high) or 0.0 (low).
            </p>
        </div>

    </div>

</section>

<!-- =======================  EXPANDED SECTION ======================= -->

<section id="logic-expanded" class="tutorial-expanded">

    <h2>Expansion 1: What Logic Does</h2>

    <details>
        <summary>Click to expand: Continuous → Discrete Conversion</summary>

        <p>
        <code>LogicProcessor</code> makes <strong>binary decisions</strong> about audio.
        </p>

        <p>
        Every sample asks:
        <em>"Is this value TRUE or FALSE?"</em>
        (based on threshold)
        </p>

        <p>
        Output: 0.0 or 1.0.
        </p>

        <p><strong>Uses:</strong></p>

        <ul>
            <li><strong>Gate</strong>: Silence audio below threshold (noise reduction)</li>
            <li><strong>Trigger</strong>: Fire events when signal crosses boundary (drums, envelopes)</li>
            <li><strong>Rhythm</strong>: Convert continuous modulation into discrete beats</li>
        </ul>

        <p>
        Example: Feed a slow LFO (0.5 Hz sine) into logic → square wave clock.
        </p>

        <p>
        Digital doesn't care what the input "means"—just whether it passes the test.
        </p>

    </details>

    <h2>Expansion 2: Logic node needs an input</h2>

    <details>
        <summary>Click to expand: Continuous → input signal</summary>

        <p>
        <code>Logic</code> nodes need an input signal to evaluate.
        This is also true for other nodes like <code>Polynomial</code>.
        </p>

        <p>
        So far, you did not have to manually set inputs because you used
        <code>ContainerBuffer</code> which automatically feeds audio into processors.
        </p>

        <p>
        So, instead of creating an <code>AudioBuffer</code>, you can load a file:
        </p>

        <pre><code class="language-cpp">
auto sound = vega.read_audio("path/to/file.wav") | Audio;
auto buffers = MayaFlux::get_last_created_container_buffers();
auto logic = vega.Logic(LogicOperator::THRESHOLD, 0.0);

auto processor = MayaFlux::create_processor&lt;LogicProcessor&gt;(
    buffer[0],
    logic
);

processor->set_modulation_type(LogicProcessor::ModulationType::REPLACE);
        </code></pre>

        <p>
        The audio from the file is automatically fed into the logic node.
        Considering how all previous examples relied on file contents,
        and the natutre of rhythmic pulses not exploiting the intricacies
        or richness of audio files,
        we are using a sine wave as inputs of the logic node in the main example.
        </p>

    </details>

    <h2>Expansion 3: LogicOperator Types</h2>

    <details>
        <summary>Click to expand: Binary Operations</summary>

        <p><code>LogicOperator</code> defines the test:</p>

        <ul>
            <li><strong>THRESHOLD</strong>: <code>x &gt; threshold</code> → 1.0, else 0.0</li>
            <li><strong>HYSTERESIS</strong>: Two thresholds (open/close) to avoid flutter</li>
            <li><strong>EDGE</strong>: Trigger on transitions (0→1 or 1→0)</li>
            <li><strong>AND/OR/XOR/NOT</strong>: Boolean algebra on current vs. previous sample</li>
            <li><strong>CUSTOM</strong>: Your function</li>
        </ul>

        <p>
        Right now you're using THRESHOLD—the simplest test.
        </p>

        <p>
        Example (hysteresis gate for noisy signals):
        </p>

        <pre><code class="language-cpp">
auto gate = vega.Logic(LogicOperator::HYSTERESIS);
gate->set_hysteresis_thresholds(0.1, 0.3);  // open at 0.3, close at 0.1
        </code></pre>

        <p>
        Signal must exceed 0.3 to open, then drops below 0.1 to close.
        Prevents rapid on/off flickering.
        </p>

    </details>

    <h2>Expansion 4: ModulationType - Readymade Transformations</h2>

    <details>
        <summary>Click to expand: Creative Logic Applications</summary>

        <p><strong>ModulationType</strong> provides readymade ways to apply binary logic to audio:</p>

        <p><strong>Basic Operations:</strong></p>

        <ul>
            <li><strong>REPLACE</strong>: Audio becomes 0.0 or 1.0 (bit reduction)</li>
            <li><strong>MULTIPLY</strong>: Audio × logic (standard gate - preserves timbre)</li>
            <li><strong>ADD</strong>: Audio + logic (adds impulse on logic high)</li>
        </ul>

        <p><strong>Creative Operations:</strong></p>

        <ul>
            <li><strong>INVERT_ON_TRUE</strong>: Phase flip when logic high (ring mod effect)</li>
            <li><strong>HOLD_ON_FALSE</strong>: Freeze audio when logic low (granular stutter)</li>
            <li><strong>ZERO_ON_FALSE</strong>: Hard silence when logic low (noise gate)</li>
            <li><strong>CROSSFADE</strong>: Smooth fade based on logic (dynamic blending)</li>
            <li><strong>THRESHOLD_REMAP</strong>: Binary amplitude switch (tremolo from logic)</li>
            <li><strong>SAMPLE_AND_HOLD</strong>: Freeze on logic changes (glitch/stutter)</li>
            <li><strong>CUSTOM</strong>: Your function</li>
        </ul>

        <p>
        Example (granular freeze effect):
        </p>

        <pre><code class="language-cpp">
processor->set_modulation_type(
    LogicProcessor::ModulationType::HOLD_ON_FALSE
);
// Audio freezes whenever logic goes low - creates stuttering repeats
        </code></pre>

        <p>
        Example (amplitude tremolo):
        </p>

        <pre><code class="language-cpp">
processor->set_modulation_type(
    LogicProcessor::ModulationType::THRESHOLD_REMAP
);
processor->set_threshold_remap_values(1.0, 0.2);
// Creates rhythmic volume changes based on logic pattern
        </code></pre>

        <p>
        Logic becomes a <strong>compositional control</strong>
        for transforming audio in musical ways.
        </p>

    </details>

    <hr>

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Hard gate (silence below threshold)
auto gate = vega.Logic(LogicOperator::THRESHOLD, 0.2);
auto proc = MayaFlux::create_processor&lt;LogicProcessor&gt;(buffer, gate);
proc->set_modulation_type(LogicProcessor::ModulationType::ZERO_ON_FALSE);

// Granular stutter (freeze on quiet passages)
auto freeze = vega.Logic(LogicOperator::THRESHOLD, 0.3);
auto proc = MayaFlux::create_processor&lt;LogicProcessor&gt;(buffer, freeze);
proc->set_modulation_type(LogicProcessor::ModulationType::HOLD_ON_FALSE);

// Bit crusher (reduce to 1-bit audio)
auto crusher = vega.Logic(LogicOperator::THRESHOLD, 0.0);
auto proc = MayaFlux::create_processor&lt;LogicProcessor&gt;(buffer, crusher);
proc->set_modulation_type(LogicProcessor::ModulationType::REPLACE);

// Rhythmic tremolo from LFO
auto lfo = vega.Sine(4.0);  // 4 Hz
auto trem_logic = vega.Logic(LogicOperator::THRESHOLD, 0.0);
trem_logic->set_input_node(lfo);
auto proc = MayaFlux::create_processor&lt;LogicProcessor&gt;(buffer, trem_logic);
proc->set_modulation_type(
    LogicProcessor::ModulationType::THRESHOLD_REMAP
);
proc->set_threshold_remap_values(1.0, 0.3);  // Pumping rhythm
    </code></pre>

</section>

<hr />


<!-- =======================  TUTORIAL SECTION ======================= -->

<section class="tutorial-section">

    <div class="tutorial-row">

        <div class="tutorial-card" data-target="combine-expanded">
            <h3 class="tutorial-title">Tutorial: Combining Polynomial + Logic</h3>
            <p class="hint">Click this card to reveal full explanation</p>

            <h4>The Pattern</h4>

            <p>
            Load a file. Detect transients with logic.
            Apply polynomial only when transient detected.
            </p>

            <pre><code class="language-cpp">
void compose() {
    auto sound = vega.read_audio("drums.wav") | Audio;
    auto buffers = MayaFlux::get_last_created_container_buffers();

    auto bitcrush = vega.Logic(LogicOperator::THRESHOLD, 0.0);
    auto crush_proc =
        MayaFlux::create_processor&lt;LogicProcessor&gt;(
            buffers[0], bitcrush
        );
    crush_proc->set_modulation_type(
        LogicProcessor::ModulationType::REPLACE
    );

    // Step 2: Freeze audio in chunks - granular stutter
    auto clock = vega.Sine(4.0); // 4 Hz freeze rate
    auto freeze_logic = vega.Logic(LogicOperator::THRESHOLD, 0.0);
    freeze_logic->set_input_node(clock);
    auto freeze_proc =
        MayaFlux::create_processor&lt;LogicProcessor&gt;(
            buffers[0], freeze_logic
        );
    freeze_proc->set_modulation_type(
        LogicProcessor::ModulationType::HOLD_ON_FALSE
    );

    // Step 3: Extreme waveshaping distortion
    auto destroyer = std::make_shared&lt;Polynomial&gt;([](double x) {
        return std::copysign(1.0, x) *
            std::pow(std::abs(x), 0.3); // Extreme compression
    });
    auto poly_proc =
        MayaFlux::create_processor&lt;PolynomialProcessor&gt;(
            buffers[0], destroyer
        );

    chain->add_processor(crush_proc, buffers[0]);
    chain->add_processor(freeze_proc, buffers[0]);
    chain->add_processor(poly_proc, buffers[0]);

    buffers[0]->set_processing_chain(chain);
}
            </code></pre>
        </div>

    </div>

</section>

<!-- =======================  EXPANDED SECTION ======================= -->

<section id="combine-expanded" class="tutorial-expanded">

    <h2>Expansion 1: Processing Chains as Transformation Pipelines</h2>

    <details>
        <summary>Click to expand: Sequential Audio Surgery</summary>

        <p>
        You just built a <strong>transformation pipeline</strong>:
        </p>

        <pre><code class="language-text">
bitcrush → freeze → destroy
        </code></pre>

        <p>
        Each processor transforms the output of the previous one.
        This is <strong>compositional signal processing</strong>—you build
        complex effects by chaining simple operations.
        </p>

        <p>The power comes from <strong>order dependency</strong>:</p>

        <pre><code class="language-text">
gate → distort    // Clean transients, heavy saturation
distort → gate    // Distorted everything, then choppy
        </code></pre>

        <p>
        Swap the order = completely different sound.
        </p>

        <p>Extend it:</p>

        <pre><code class="language-text">
detect transients → sample-and-hold → bitcrush → wavefold → compress
        </code></pre>

        <p>
        Traditional plugins give you "distortion with 3 knobs."
        You compose the distortion algorithm itself.
        </p>

        <p>
        <strong>Every processor is a building block.</strong>
        Chain them to create effects that don't exist as plugins:
        </p>

        <ul>
            <li>Bitcrush → Freeze → Invert = Glitch stutterer</li>
            <li>Remap → Fold → Gate = Rhythmic harmonizer</li>
            <li>Threshold → Hold → Distort = Transient emphasizer</li>
        </ul>

        <p>
        Logic + Polynomial + Chains =
        <strong>programmable audio transformation system</strong>.
        </p>

    </details>

    <h2>Expansion 2: Chain Order Matters</h2>

    <details>
        <summary>Click to expand: Non-Commutative Processing</summary>

        <p>
        Swap the order of logic and polynomial → different result:
        </p>

        <pre><code class="language-text">
Logic → Polynomial  // Detect, then distort
Polynomial → Logic  // Distort, then detect
        </code></pre>

        <p>
        Processors are <strong>non-commutative</strong>.
        Audio math doesn't follow algebra rules.
        </p>

        <p>
        Order determines signal flow.
        You're building a graph, not an equation.
        </p>

    </details>

    <hr>

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Adaptive dynamics (compress quiet, expand loud)
auto logic = vega.Logic(LogicOperator::THRESHOLD, 0.3);
auto poly_compress =
    vega.Polynomial([](double x) { return x * 2.0; });
auto poly_expand =
    vega.Polynomial([](double x) { return x * 0.5; });

// Route based on logic state (requires custom modulation)
    </code></pre>

</section>

<hr />

<!-- =======================  TUTORIAL SECTION ======================= -->

<section class="tutorial-section">

    <div class="tutorial-row">

        <div class="tutorial-card" data-target="chains-expanded">
            <h3 class="tutorial-title">Tutorial: Processing Chains and Buffer Architecture</h3>
            <p class="hint">Click this card to reveal full explanation</p>

            <h4>Tutorial: Explicit Chain Building</h4>

            <h5>The Simplest Path</h5>

            <p>
            You've been adding processors one at a time.
            Now control their order explicitly.
            </p>

            <pre><code class="language-cpp">
void compose() {
    auto sound = vega.read_audio("path/to/file.wav") | Audio;
    auto buffer = MayaFlux::get_last_created_container_buffers()[0];

    // Create an empty chain
    auto chain = MayaFlux::create_processing_chain();

    // Build the chain: Distortion → Gate → Compression
    auto distortion =
        vega.Polynomial([](double x) { return std::tanh(x * 2.0); });
    auto gate =
        vega.Logic(LogicOperator::THRESHOLD, 0.1);
    auto compression =
        vega.Polynomial([](double x) {
            return x / (1.0 + std::abs(x));
        });

    chain->add_processor(
        std::make_shared&lt;PolynomialProcessor&gt;(distortion),
        buffer
    );
    chain->add_processor(
        std::make_shared&lt;LogicProcessor&gt;(gate),
        buffer
    );
    chain->add_processor(
        std::make_shared&lt;PolynomialProcessor&gt;(compression),
        buffer
    );

    // Attach the chain to the buffer
    buffer->set_processing_chain(chain);
}
            </code></pre>

            <p>
            Run this. You hear:
            clean audio → saturated → gated (silence below threshold)
            → compressed (controlled peaks).
            </p>

            <p><strong>Swap the order:</strong></p>

            <pre><code class="language-cpp">
chain->add_processor(gate_processor);       // Gate first
chain->add_processor(distortion_processor); // Then distort
chain->add_processor(compression_processor);
            </code></pre>

            <p>
            Different sound.
            Order matters.
            </p>

        </div>

    </div>

</section>

<!-- =======================  EXPANDED SECTION ======================= -->

<section id="chains-expanded" class="tutorial-expanded">

    <h2>Expansion 1: What <code>create_processor()</code> Was Doing</h2>

    <details>
        <summary>Click to expand: Implicit vs. Explicit Chain Management</summary>

        <p>Previously, when you wrote:</p>

        <pre><code class="language-cpp">
auto processor =
    MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffer, poly);
        </code></pre>

        <p>MayaFlux did this behind the scenes:</p>

        <ol>
            <li>Created the processor</li>
            <li>Got the buffer's existing processing chain</li>
            <li><strong>Automatically added the processor to that chain</strong></li>
            <li>Returned the processor</li>
        </ol>

        <p>
        You didn't see this because it was implicit.
        The processor was silently appended to whatever chain existed.
        </p>

        <p><strong>Now you're building chains explicitly:</strong></p>

        <pre><code class="language-cpp">
auto chain = MayaFlux::create_processing_chain();  // Empty chain
chain->add_processor(proc1);  // Manual control
chain->add_processor(proc2);
buffer->set_processing_chain(chain);  // Replace buffer's chain
        </code></pre>

        <p><strong>When to use explicit chains:</strong></p>

        <ul>
            <li>You need precise order control</li>
            <li>You're building reusable processor "presets"</li>
            <li>You want to swap entire chains dynamically (e.g., switch between clean/distorted modes)</li>
            <li>You're debugging processor interactions</li>
        </ul>

        <p><strong>When implicit is fine:</strong></p>

        <ul>
            <li>Simple cases (1-2 processors)</li>
            <li>Order doesn't matter (parallel-like effects)</li>
            <li>Rapid prototyping</li>
        </ul>

    </details>

    <h2>Expansion 2: Chain Execution Order</h2>

    <details>
        <summary>Click to expand: Sequential Data Flow</summary>

        <p>Chains execute like a for-loop over processors:</p>

        <pre><code class="language-cpp">
for (auto& processor : chain->get_processors()) {
    processor->process(buffer);
}
        </code></pre>

        <p>Data flows sequentially:</p>

        <pre><code class="language-text">
Container → Buffer (512 samples)
    ↓
Processor₁: Distortion (modifies samples in-place)
    ↓
Processor₂: Gate (zeroes out quiet samples)
    ↓
Processor₃: Compression (reduces peaks)
    ↓
Speakers
        </code></pre>

        <p>
        Each processor sees the <strong>output</strong>
        of the previous processor.
        </p>

        <p>
        <strong>This is not parallel processing.</strong>
        No branches. No simultaneous paths.
        Pure sequential transformation.
        </p>

        <p>
        (Parallel routing requires <code>BufferPipeline</code>—covered in a later tutorial.)
        </p>

    </details>

    <h2>Expansion 3: Default Processors vs. Chain Processors</h2>

    <details>
        <summary>Click to expand: The Two-Stage Processing Model</summary>

        <p>Every buffer has two processing stages:</p>

        <p><strong>Stage 1: Default Processor</strong> (runs first, always)</p>

        <ul>
            <li>Defined by buffer type</li>
            <li>Handles data <strong>acquisition</strong> or <strong>generation</strong></li>
            <li>Examples:
                <ul>
                    <li><code>ContainerBuffer</code>: reads from file/stream</li>
                    <li><code>NodeBuffer</code>: evaluates a node</li>
                    <li><code>FeedbackBuffer</code>: mixes current + previous buffer</li>
                    <li><code>AudioBuffer</code>: none (generic accumulator)</li>
                </ul>
            </li>
        </ul>

        <p><strong>Stage 2: Processing Chain</strong> (runs second)</p>

        <ul>
            <li>Your custom processors</li>
            <li>Handles data <strong>transformation</strong></li>
            <li>Examples: filters, waveshaping, logic, etc.</li>
        </ul>

        <p><strong>Execution flow:</strong></p>

        <pre><code class="language-text">
1. Buffer's default processor runs (fills buffer with data)
2. Processing chain runs (transforms that data)
3. Result goes to speakers
        </code></pre>

        <p>
        When you add processors via <code>create_processor()</code>,
        they go into <strong>Stage 2</strong> (the chain).
        </p>

        <p>
        The <strong>default processor</strong> is fixed per buffer type.
        You can replace it, but usually you don't need to—the chain
        is where creativity happens.
        </p>

    </details>

    <hr>

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Stack multiple distortions (cascading saturation)
auto chain = MayaFlux::create_processing_chain();
auto light =
    vega.Polynomial([](double x) { return std::tanh(x * 1.5); });
auto heavy =
    vega.Polynomial([](double x) { return std::tanh(x * 5.0); });
auto fold =
    vega.Polynomial([](double x) { return std::sin(x * 3.0); });

chain->add_processor(
    std::make_shared&lt;PolynomialProcessor&gt;(light),
    buffer
);
chain->add_processor(
    std::make_shared&lt;PolynomialProcessor&gt;(heavy),
    buffer
);
chain->add_processor(
    std::make_shared&lt;PolynomialProcessor&gt;(fold),
    buffer
);

// Insert gating between stages
auto gate = vega.Logic(LogicOperator::THRESHOLD, 0.2);
chain->add_processor(
    std::make_shared&lt;PolynomialProcessor&gt;(light),
    buffer
);
chain->add_processor(
    std::make_shared&lt;LogicProcessor&gt;(gate),
    buffer
);  // Gate the distortion
chain->add_processor(
    std::make_shared&lt;PolynomialProcessor&gt;(heavy),
    buffer
); // Distort the gated signal

buffer->set_processing_chain(chain);
    </code></pre>

</section>

<!-- ======================= PARENT CARD: BUFFER TYPES ======================= -->

<section class="tutorial-section">
    <!-- <div class="tutorial-card tutorial-parent" data-target="buffer-types-expanded"> -->
    <div class="tutorial-card tutorial-parent">
      <h3 class="tutorial-title">Tutorial: Various Buffer Types</h3>
      <!-- <p class="hint">Click this card to reveal all buffer type tutorials</p> -->
      
      <h4>Buffer Ecosystem Overview</h4>
      <p>MayaFlux provides specialized buffer types for different generation and processing patterns:</p>
      <ul>
        <li><strong>NodeBuffer</strong>: Generate audio from mathematical nodes</li>
        <li><strong>FeedbackBuffer</strong>: Recursive temporal processing with memory</li>
        <li><strong>StreamWriteProcessor</strong>: Capture processed audio to containers</li>
      </ul>
      <p>Each buffer type has default processors and specific use cases. Click to explore each in detail.</p>

<!-- ======================= EXPANDED SECTION: CHILD CARDS ======================= -->

<!-- <section id="buffer-types-expanded" class="tutorial-section"> -->
  
  <!-- =================== CHILD CARD 1: NodeBuffer =================== -->
  
  <div class="tutorial-row">
    <div class="tutorial-card" data-target="nodebuffer-detail">
      <h3 class="tutorial-title">Generating from Nodes (NodeBuffer)</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Next Pattern</h4>

      <p>So far: buffers read from files, nodes affect buffer processing.<br>
      Now: buffers <strong>generate</strong> from nodes.</p>

      <pre><code class="language-cpp">
void compose() {
    // Create a sine node
    auto sine = vega.Sine(440.0);

    // Create a NodeBuffer that captures the sine's output
    auto node_buffer = vega.NodeBuffer(0, 512, sine)[0] | Audio;

    // Add processing to the generated audio
    auto distortion = vega.Polynomial([](double x) { return x * x * x; });
    MayaFlux::create_processor&lt;PolynomialProcessor&gt;(node_buffer, distortion);
}
      </code></pre>

      <p>Run this. You hear a 440 Hz sine wave with cubic distortion.</p>

      <p>No file loaded. The buffer <strong>generates</strong> audio by evaluating the node 512 times per cycle.</p>
    </div>
  </div>

  <!-- NodeBuffer Expanded Details -->
  <section id="nodebuffer-detail" class="tutorial-expanded">
    <h2>Expansion 1: What NodeBuffer Does</h2>

    <details>
      <summary>Click to expand: Nodes → Buffers Bridge</summary>

      <p><code>NodeBuffer</code> connects the <strong>node system</strong> (sample-by-sample evaluation) to the <strong>buffer system</strong> (block-based processing).</p>

      <p><strong>Default processor: <code>NodeSourceProcessor</code></strong></p>

      <p>Each cycle:</p>

      <ol>
        <li>Node is evaluated 512 times: <code>node-&gt;process_sample()</code></li>
        <li>Results fill the buffer</li>
        <li>Processing chain runs (your custom processors)</li>
        <li>Buffer outputs to speakers</li>
      </ol>

      <p><strong>Why this matters:</strong></p>

      <p>Nodes are mathematical expressions—infinite generators. Buffers are temporal accumulators—finite chunks.</p>

      <p><code>NodeBuffer</code> bridges the two: <strong>continuous expression → discrete blocks</strong>.</p>

      <p>Without <code>NodeBuffer</code>, you'd manually call <code>node-&gt;process_sample()</code> 512 times and copy results into a buffer. <code>NodeBuffer</code> automates this.</p>
    </details>

    <h2>Expansion 2: The <code>clear_before_process</code> Parameter</h2>

    <details>
      <summary>Click to expand: Accumulation vs. Replacement</summary>

      <p><code>NodeBuffer</code> has a flag: <code>clear_before_process</code></p>

      <pre><code class="language-cpp">
auto node_buffer = vega.NodeBuffer(0, 512, sine, true);  // Clear first (default)
      </code></pre>

      <p><strong>true (default)</strong>: Buffer is zeroed, then filled with node output</p>
      <ul>
        <li>Result: pure node output</li>
      </ul>

      <p><strong>false</strong>: Node output is <strong>added</strong> to existing buffer content</p>
      <ul>
        <li>Result: node output + previous buffer state</li>
      </ul>

      <p>Why use <code>false</code>?</p>

      <ul>
        <li><strong>Layering</strong>: Multiple nodes contributing to the same buffer</li>
        <li><strong>Feedback</strong>: Previous cycle's output influences current cycle</li>
        <li><strong>Additive synthesis</strong>: Mix multiple generators</li>
      </ul>

      <p>Example (layering):</p>

      <pre><code class="language-cpp">
auto sine = vega.Sine(440.0);
auto buffer = vega.NodeBuffer(0, 512, sine, true)[0] | Audio;  // First node clears

auto noise = vega.Random();
auto noise_buffer = vega.NodeBuffer(0, 512, noise, false)[0] | Audio;  // Adds to sine
      </code></pre>

      <p>Result: sine + noise.</p>
    </details>

    <h2>Expansion 3: NodeSourceProcessor Mix Parameter</h2>

    <details>
      <summary>Click to expand: Interpolation Between Existing and Incoming Data</summary>

      <p><code>NodeSourceProcessor</code> has a <code>mix</code> parameter (default: 0.5):</p>

      <pre><code class="language-cpp">
auto processor = std::make_shared&lt;NodeSourceProcessor&gt;(node, 0.7f);
      </code></pre>

      <p><strong>Mix = 0.0</strong>: Preserve existing buffer content (node output ignored)<br>
      <strong>Mix = 0.5</strong>: Equal blend of existing + node output<br>
      <strong>Mix = 1.0</strong>: Replace with node output (existing content overwritten)</p>

      <p>This is a <strong>cross-fade</strong> between what's in the buffer and what the node generates.</p>

      <p><strong>Use case</strong>: Smoothly transition between sources, or create feedback loops where node output gradually replaces decaying buffer content.</p>

      <p>Most of the time, you'll use the default (1.0 via <code>clear_before_process=true</code>). But for creative effects, <code>mix</code> is powerful.</p>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Additive synthesis (multiple generators in one buffer)
auto fund = vega.Sine(220.0);
auto harm2 = vega.Sine(440.0);
auto harm3 = vega.Sine(660.0);

auto buffer = vega.NodeBuffer(0, 512, fund, true)[0] | Audio;   // First clears
vega.NodeBuffer(0, 512, harm2, false)[0] | Audio;  // Adds harmonic 2
vega.NodeBuffer(0, 512, harm3, false)[0] | Audio;  // Adds harmonic 3

// Waveshaping a generated tone
auto sine = vega.Sine(110.0);
auto buffer2 = vega.NodeBuffer(0, 512, sine)[1] | Audio;
auto waveshape = vega.Polynomial([](double x) { return std::tanh(x * 10.0); });
MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffer2, waveshape);
    </code></pre>
  </section>

  <!-- =================== CHILD CARD 2: FeedbackBuffer =================== -->

  <div class="tutorial-row">
    <div class="tutorial-card" data-target="feedbackbuffer-detail">
      <h3 class="tutorial-title">FeedbackBuffer (Recursive Audio)</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Pattern</h4>

      <p>Buffers that <strong>remember</strong> their previous state.</p>

      <pre><code class="language-cpp">
void compose() {
    // FeedbackBuffer: 70% feedback, 512 samples delay
    auto feedback_buf = vega.FeedbackBuffer(0, 512, 0.7f, 512)[0] | Audio;

    // Feed an impulse into the buffer to kick-start resonance
    auto impulse = vega.Impulse(2.0);  // 2 Hz pulse train
    vega.NodeBuffer(0, 512, impulse, false)[0] | Audio;  // Adds to feedback buffer

    // WARN: Remember to turn OFF after a few seconds as feedback can build up!
}
      </code></pre>

      <p>Run this. You hear: repeating echoes, each 70% of the previous amplitude.</p>

      <p>The buffer <strong>feeds back into itself</strong>—output becomes input next cycle.</p>
    </div>
  </div>

  <!-- FeedbackBuffer Expanded Details -->
  <section id="feedbackbuffer-detail" class="tutorial-expanded">
    <h2>Expansion 1: What FeedbackBuffer Does</h2>

    <details>
      <summary>Click to expand: Recursive Temporal Processing</summary>

      <p><strong>Default processor: <code>FeedbackProcessor</code></strong></p>

      <p>Each cycle:</p>

      <ol>
        <li>Current buffer content: <code>buffer[n]</code></li>
        <li>Previous buffer content: <code>previous_buffer[n-1]</code></li>
        <li>Output: <code>buffer[n] + (feedback_amount * previous_buffer[n-1])</code></li>
        <li>Store output as next cycle's "previous"</li>
      </ol>

      <p>This is a <strong>simple delay line</strong> with feedback.</p>

      <p><strong>Parameters:</strong></p>

      <ul>
        <li><code>feedback_amount</code>: 0.0–1.0 (how much previous state contributes)</li>
        <li><code>feed_samples</code>: Delay length in samples</li>
      </ul>

      <p>Example: <code>FeedbackBuffer(0, 512, 0.7, 512)</code> creates:</p>

      <ul>
        <li>512-sample delay (~10.6 ms at 48 kHz)</li>
        <li>70% feedback (echoes decay to 0.7 → 0.49 → 0.343 → ...)</li>
      </ul>

      <p><strong>Stability:</strong> Keep <code>feedback_amount &lt; 1.0</code> or output will grow unbounded.</p>
    </details>

    <h2>Expansion 2: FeedbackBuffer Limitations</h2>

    <details>
      <summary>Click to expand: What FeedbackBuffer Cannot Do</summary>

      <p><code>FeedbackBuffer</code> is simple—intentionally. It implements <strong>one specific recursive algorithm</strong>: linear feedback delay.</p>

      <p><strong>Limitations:</strong></p>

      <ol>
        <li><strong>Fixed feedback coefficient</strong>: Can't modulate feedback amount per sample (it's buffer-wide)</li>
        <li><strong>No filtering in loop</strong>: Can't insert lowpass/highpass in the feedback path</li>
        <li><strong>No cross-channel feedback</strong>: Single-channel only</li>
        <li><strong>No time-varying delay</strong>: Delay length is fixed at creation</li>
      </ol>

      <p><strong>Why these limitations?</strong></p>

      <p><code>FeedbackBuffer</code> is a <strong>building block</strong>, not a complete reverb/delay effect.</p>

      <p>For complex feedback systems:</p>

      <ul>
        <li>Use <code>PolynomialProcessor</code> in <code>RECURSIVE</code> mode (per-sample nonlinear feedback)</li>
        <li>Use <code>BufferPipeline</code> to route buffers back to themselves with processing</li>
        <li>Build custom feedback networks with multiple buffers</li>
      </ul>

      <p><code>FeedbackBuffer</code> is for <strong>simple echoes and resonances</strong>—quick and efficient.</p>
    </details>

    <h2>Expansion 3: When to Use FeedbackBuffer</h2>

    <details>
      <summary>Click to expand: Use Cases and Alternatives</summary>

      <p><strong>Use <code>FeedbackBuffer</code> when:</strong></p>

      <ul>
        <li>You need a simple delay line with fixed feedback</li>
        <li>Building Karplus-Strong string synthesis</li>
        <li>Creating rhythmic echoes</li>
        <li>Implementing comb filters</li>
      </ul>

      <p><strong>Use <code>PolynomialProcessor(RECURSIVE)</code> when:</strong></p>

      <ul>
        <li>You need nonlinear feedback (saturation, distortion in loop)</li>
        <li>Feedback amount varies per sample</li>
        <li>Building filters with arbitrary feedback functions</li>
      </ul>

      <p><strong>Use <code>BufferPipeline</code> when:</strong></p>

      <ul>
        <li>You need complex routing (buffer A → process → buffer B → back to A)</li>
        <li>Multi-buffer feedback networks</li>
        <li>Cross-channel feedback</li>
      </ul>

      <p><strong>Example: Filtered feedback (requires multiple approaches):</strong></p>

      <pre><code class="language-cpp">
// FeedbackBuffer can't do this alone:
// current + lowpass(feedback * previous)

// Solution: Use PolynomialProcessor RECURSIVE mode with filtering
auto filtered_feedback = vega.Polynomial(
    [](std::span&lt;double&gt; amp; history) {
        double fb = 0.7 * history[0];
        return fb * 0.5 + history[1] * 0.5;  // Simple lowpass
    },
    PolynomialMode::RECURSIVE,
    2
);
      </code></pre>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Karplus-Strong string (plucked string synthesis)
auto feedback_buf = vega.FeedbackBuffer(0, 512, 0.996f, 100)[0] | Audio;  // ~480 Hz
// Excite with noise burst
auto noise = vega.Random();
vega.NodeBuffer(0, 512, noise, false)[0] | Audio;

// Ping-pong delay (requires two buffers—teaser for later)
// auto left = vega.FeedbackBuffer(0, 512, 0.6f, 2400)[0] | Audio;
// auto right = vega.FeedbackBuffer(1, 512, 0.6f, 2400)[1] | Audio;
// Route left → right, right → left (needs BufferPipeline)

// Resonant comb filter
auto feedback_buf2 = vega.FeedbackBuffer(0, 512, 0.95f, 50)[1] | Audio;
auto input = vega.Sine(220.0);
vega.NodeBuffer(0, 512, input, false)[1] | Audio;
    </code></pre>
  </section>

  <!-- =================== CHILD CARD 3: StreamWriteProcessor =================== -->

  <div class="tutorial-row">
    <div class="tutorial-card" data-target="streamwrite-detail">
      <h3 class="tutorial-title">StreamWriteProcessor (Capturing Audio)</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Pattern</h4>

      <p>Processors that <strong>write</strong> buffer data somewhere (instead of transforming it).</p>

      <pre><code class="language-cpp">
void compose() {
    auto sound = vega.read_audio("path/to/file.wav") | Audio;
    auto buffer = MayaFlux::get_last_created_container_buffers()[0];

    // Create a DynamicSoundStream (accumulator for captured audio)
    auto capture_stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 2);

    // Create a processor that writes buffer data to the stream
    auto writer = std::make_shared&lt;StreamWriteProcessor&gt;(capture_stream);

    // Add to buffer's processing chain
    auto chain = buffer-&gt;get_processing_chain();
    chain-&gt;add_processor(writer);

    // File plays AND is captured to stream simultaneously
}
      </code></pre>

      <p>Run this. The file plays <strong>and</strong> is written to <code>capture_stream</code> every cycle.</p>

      <p>After playback, <code>capture_stream</code> contains a copy of the entire file (processed through any other processors in the chain before the writer).</p>
    </div>
  </div>

  <!-- StreamWriteProcessor Expanded Details -->
  <section id="streamwrite-detail" class="tutorial-expanded">
    <h2>Expansion 1: What StreamWriteProcessor Does</h2>

    <details>
      <summary>Click to expand: Buffers → Containers Bridge</summary>

      <p><code>StreamWriteProcessor</code> is the <strong>inverse</strong> of <code>ContainerBuffer</code>:</p>

      <ul>
        <li><strong>ContainerBuffer</strong>: reads from container → fills buffer (source)</li>
        <li><strong>StreamWriteProcessor</strong>: reads from buffer → writes to container (sink)</li>
      </ul>

      <p><strong>Each cycle:</strong></p>

      <ol>
        <li>Extract 512 samples from the buffer</li>
        <li>Write them to the <code>DynamicSoundStream</code> at the current write position</li>
        <li>Increment write position by 512</li>
      </ol>

      <p>The stream grows dynamically as data arrives. No pre-allocation needed (though you can for performance).</p>

      <p><strong>Use cases:</strong></p>

      <ul>
        <li>Record processed audio to memory</li>
        <li>Capture intermediate processing stages for analysis</li>
        <li>Build delay lines / loopers</li>
        <li>Create feedback paths (buffer → stream → buffer)</li>
      </ul>
    </details>

    <h2>Expansion 2: Channel-Aware Writing</h2>

    <details>
      <summary>Click to expand: Multi-Channel Capture</summary>

      <p><code>StreamWriteProcessor</code> respects buffer channel IDs:</p>

      <pre><code class="language-cpp">
auto left_buffer = buffers[0];   // channel 0
auto right_buffer = buffers[1];  // channel 1

auto stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 2);  // stereo

auto writer_L = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
auto writer_R = std::make_shared&lt;StreamWriteProcessor&gt;(stream);

// Add to respective buffers
left_buffer-&gt;get_processing_chain()-&gt;add_processor(writer_L);
right_buffer-&gt;get_processing_chain()-&gt;add_processor(writer_R);
      </code></pre>

      <p>Result: Stereo file captured to stereo stream—channels preserved.</p>

      <p><strong>Critical:</strong> Buffer's <code>channel_id</code> determines which stream channel receives data. Mismatch = warning + skip.</p>
    </details>

    <h2>Expansion 3: Position Management</h2>

    <details>
      <summary>Click to expand: Write Position Control</summary>

      <p><code>StreamWriteProcessor</code> tracks where it's writing:</p>

      <pre><code class="language-cpp">
writer-&gt;set_write_position(0);        // Write from start
writer-&gt;set_write_position(48000);    // Write from 1-second mark
writer-&gt;reset_position();             // Reset to 0

// Time-based positioning
writer-&gt;set_write_position_time(2.5); // Write from 2.5 seconds

uint64_t pos = writer-&gt;get_write_position();           // Get current frame position
double time = writer-&gt;get_write_position_time();       // Get current time position
      </code></pre>

      <p><strong>Why control position?</strong></p>

      <ul>
        <li><strong>Overdubbing</strong>: Write new audio over existing content</li>
        <li><strong>Looping</strong>: Reset position to create cyclic recording</li>
        <li><strong>Multi-pass recording</strong>: Capture different takes at different positions</li>
      </ul>

      <p>Default behavior: append at end. Position auto-increments.</p>
    </details>

    <h2>Expansion 4: Circular Mode</h2>

    <details>
      <summary>Click to expand: Fixed-Size Circular Buffers</summary>

      <p><code>DynamicSoundStream</code> can operate in <strong>circular mode</strong>:</p>

      <pre><code class="language-cpp">
auto stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 2);
stream-&gt;enable_circular_buffer(48000);  // 1 second capacity

auto writer = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
      </code></pre>

      <p><strong>Behavior:</strong></p>

      <p>When write position reaches capacity, it wraps to 0. Old data is overwritten.</p>

      <p><strong>Use cases:</strong></p>

      <ul>
        <li><strong>Delay lines</strong>: Fixed-length delays for effects</li>
        <li><strong>Loopers</strong>: Record N seconds, then loop</li>
        <li><strong>Rolling analysis</strong>: Keep only the most recent N seconds</li>
      </ul>

      <p>Without circular mode, the stream grows unbounded—useful for full recording, problematic for long-running systems.</p>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Record 5 seconds of audio
auto sound = vega.read_audio("path/to/file.wav") | Audio;
auto buffer = MayaFlux::get_last_created_container_buffers()[0];

auto stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 1);
stream-&gt;ensure_capacity(48000 * 5);  // Pre-allocate 5 seconds

auto writer = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
buffer-&gt;get_processing_chain()-&gt;add_processor(writer, buffer);

// After playback, stream contains the audio
// You can analyze it, write to disk, or feed it back

// Circular delay (1 second)
auto stream2 = std::make_shared&lt;DynamicSoundStream&gt;(48000, 1);
stream2-&gt;enable_circular_buffer(48000);  // Loop after 1 second

auto writer2 = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
buffer-&gt;get_processing_chain()-&gt;add_processor(writer, buffer);

// Stream now acts as a 1-second tape loop
    </code></pre>
  </section>

  <!-- =================== CLOSING SUMMARY =================== -->

  <hr />

  <h2>Closing: The Buffer Ecosystem</h2>

  <p>You now understand:</p>

  <p><strong>Buffer Types:</strong></p>

  <ul>
    <li><code>AudioBuffer</code>: Generic accumulator</li>
    <li><code>ContainerBuffer</code>: Reads from files/streams (default: <code>ContainerToBufferAdapter</code>)</li>
    <li><code>NodeBuffer</code>: Generates from nodes (default: <code>NodeSourceProcessor</code>)</li>
    <li><code>FeedbackBuffer</code>: Recursive delay (default: <code>FeedbackProcessor</code>)</li>
  </ul>

  <p><strong>Processor Types:</strong></p>

  <ul>
    <li><code>PolynomialProcessor</code>: Waveshaping, filters, recursive math</li>
    <li><code>LogicProcessor</code>: Decisions, gates, triggers</li>
    <li><code>StreamWriteProcessor</code>: Capture to containers</li>
  </ul>

  <p><strong>Processing Flow:</strong></p>

  <pre><code>
Default Processor (acquire/generate data)
    ↓
Processing Chain (transform data)
    ↓
Output (speakers/containers/other buffers)
  </code></pre>

  <p><strong>Next:</strong> Buffer routing, cloning, and supply mechanics—how to send processed buffers to multiple channels/domains.</p>

<!-- </div> -->
<!-- </section> -->
</div>
</section>

<!-- ======================= PARENT CARD: AUDIO INPUT, ROUTING, AND DISTRIBUTION ======================= -->

<section class="tutorial-section">
    <div class="tutorial-card tutorial-parent">
    <!-- <div class="tutorial-card tutorial-parent" data-target="routing-expanded"> -->
      <h3 class="tutorial-title">Tutorial: Audio Input, Routing, and Multi-Channel Distribution</h3>
      <!-- <p class="hint">Click this card to reveal all routing and distribution tutorials</p> -->
      
      <h4>Routing Ecosystem Overview</h4>
      <p>MayaFlux provides sophisticated routing capabilities for capturing, distributing, and cloning audio across multiple channels:</p>
      <ul>
        <li><strong>Audio Input</strong>: Capture live microphone input with real-time processing</li>
        <li><strong>Buffer Supply</strong>: Route one buffer to multiple output channels efficiently</li>
        <li><strong>Buffer Cloning</strong>: Create independent copies for parallel processing</li>
      </ul>
      <p>These systems enable complex signal routing, multi-channel processing, and efficient resource utilization. Click to explore each in detail.</p>

<!-- ======================= EXPANDED SECTION: CHILD CARDS ======================= -->

<!-- <section id="routing-expanded" class="tutorial-expanded"> -->
  
  <!-- =================== CHILD CARD 1: Audio Input =================== -->
  
  <div class="tutorial-row">
    <div class="tutorial-card" data-target="audioinput-detail">
      <h3 class="tutorial-title">Capturing Audio Input</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Simplest Path</h4>

      <p>So far: buffers read from files or generate from nodes. Now: capture from your microphone.</p>

      <pre><code class="language-cpp">
void settings() {
    auto&amp; stream = MayaFlux::Config::get_global_stream_info();
    stream.input.enabled = true;   // Enable microphone input
    stream.input.channels = 1;      // Mono input
}

void compose() {
    // Create a buffer that listens to microphone channel 0
    auto mic_buffer = MayaFlux::create_input_listener_buffer(0, true);

    // Add processing to the live input
    auto distortion = vega.Polynomial([](double x) { return std::tanh(x * 3.0); });
    MayaFlux::create_processor&lt;PolynomialProcessor&gt;(mic_buffer, distortion);
}
      </code></pre>

      <p>Run this. Speak into your microphone. You hear yourself with distortion applied in real-time.</p>
    </div>
  </div>

  <!-- Audio Input Expanded Details -->
  <section id="audioinput-detail" class="tutorial-expanded">
    <h2>Expansion 1: What <code>create_input_listener_buffer()</code> Does</h2>

    <details>
      <summary>Click to expand: Input System Architecture</summary>

      <p>MayaFlux has a dedicated <strong>input subsystem</strong> parallel to the output system.</p>

      <p><strong>Architecture:</strong></p>

      <pre><code>
Hardware (Microphone)
    ↓
Audio Driver (RtAudio)
    ↓
BufferManager::process_input()
    ↓
InputAudioBuffer (per input channel)
    ↓
InputAccessProcessor (dispatches to listeners)
    ↓
Your listener buffers
      </code></pre>

      <p>When you call <code>create_input_listener_buffer(channel, add_to_output)</code>:</p>

      <ol>
        <li>Creates a new <code>AudioBuffer</code></li>
        <li>Registers it with <code>InputAudioBuffer[channel]</code> as a <strong>listener</strong></li>
        <li>If <code>add_to_output=true</code>: Also registers it with output channel (so it plays back)</li>
      </ol>

      <p><strong>Each audio cycle:</strong></p>

      <ul>
        <li>Driver captures microphone data</li>
        <li><code>InputAudioBuffer</code> receives it</li>
        <li><code>InputAccessProcessor</code> <strong>copies</strong> data to all registered listeners</li>
        <li>Your buffer gets fresh input every cycle</li>
      </ul>

      <p><strong>Key insight:</strong> <code>InputAudioBuffer</code> is a <strong>hub</strong>. Multiple buffers can listen to the same input channel simultaneously.</p>
    </details>

    <h2>Expansion 2: Manual Input Registration</h2>

    <details>
      <summary>Click to expand: Fine-Grained Control</summary>

      <p><code>create_input_listener_buffer()</code> is convenience. You can do it manually:</p>

      <pre><code class="language-cpp">
// Create your own buffer
auto buffer = vega.AudioBuffer()[0] | Audio;

// Register it as input listener
MayaFlux::read_from_audio_input(buffer, 0);  // Listen to input channel 0

// Later, stop listening:
MayaFlux::detach_from_audio_input(buffer, 0);
      </code></pre>

      <p><strong>When to use manual registration:</strong></p>

      <ul>
        <li>You already have a buffer (don't want to create a new one)</li>
        <li>You want to dynamically start/stop listening (e.g., record button)</li>
        <li>You need finer control over buffer lifecycle</li>
      </ul>

      <p><strong>Example: Record button</strong></p>

      <pre><code class="language-cpp">
auto recorder = vega.AudioBuffer()[0] | Audio;

// Start recording
MayaFlux::read_from_audio_input(recorder, 0);

// Stop recording (after some time)
MayaFlux::detach_from_audio_input(recorder, 0);
      </code></pre>

      <p>The buffer continues to exist and process, but stops receiving new input.</p>
    </details>

    <h2>Expansion 3: Input Without Playback</h2>

    <details>
      <summary>Click to expand: Silent Capture</summary>

      <p>Often you want to <strong>capture</strong> input without <strong>playing</strong> it back:</p>

      <pre><code class="language-cpp">
// Create listener but don't add to output
auto mic_capture = MayaFlux::create_input_listener_buffer(0, false);  // false = silent

// Capture to a stream for analysis
auto stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 1);
auto writer = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
mic_capture-&gt;get_processing_chain()-&gt;add_processor(writer);
      </code></pre>

      <p><strong>Result:</strong> Microphone data is captured to <code>stream</code>, but you don't hear it.</p>

      <p><strong>Use cases:</strong></p>

      <ul>
        <li>Recording without monitoring</li>
        <li>Voice analysis (pitch detection, speech recognition)</li>
        <li>Trigger detection (clap to start/stop)</li>
        <li>Level metering / VU display</li>
      </ul>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Real-time vocal effects chain
auto mic = MayaFlux::create_input_listener_buffer(0, true);

auto pitch_shift = vega.Polynomial([](double x) { return x * 1.5; });  // Naive pitch shift
auto reverb = vega.FeedbackBuffer(0, 512, 0.3f, 2400);  // Simple reverb
auto gate = vega.Logic(LogicOperator::THRESHOLD, 0.05);  // Noise gate

MayaFlux::create_processor&lt;PolynomialProcessor&gt;(mic, pitch_shift);
MayaFlux::create_processor&lt;LogicProcessor&gt;(mic, gate);

// Record to disk simultaneously
auto stream = std::make_shared&lt;DynamicSoundStream&gt;(48000, 1);
auto writer = std::make_shared&lt;StreamWriteProcessor&gt;(stream);
mic-&gt;get_processing_chain()-&gt;add_processor(writer, mic);
// After session: save 'stream' to file

// Voice-triggered synthesis
auto mic_silent = MayaFlux::create_input_listener_buffer(0, false);
auto trigger = vega.Logic(LogicOperator::EDGE);
trigger-&gt;set_edge_detection(EdgeType::RISING, 0.3);
auto trigger_proc = MayaFlux::create_processor&lt;LogicProcessor&gt;(mic_silent, trigger);

// When trigger fires, start a synthesizer...
    </code></pre>
  </section>

  <!-- =================== CHILD CARD 2: Buffer Supply =================== -->

  <div class="tutorial-row">
    <div class="tutorial-card" data-target="buffersupply-detail">
      <h3 class="tutorial-title">Buffer Supply (Routing to Multiple Channels)</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Pattern</h4>

      <p>One buffer, multiple output channels.</p>

      <pre><code class="language-cpp">
void compose() {
    auto sine = vega.Sine(440.0);
    auto buffer = vega.NodeBuffer(0, 512, sine)[0] | Audio;  // Registered to channel 0

    // Supply this buffer to channels 1 and 2 as well
    MayaFlux::supply_buffer_to_channels(buffer, {1, 2}, 0.5);  // 50% mix level
}
      </code></pre>

      <p>Run this. You hear the same 440 Hz sine on <strong>all three channels</strong> (left, center, right in surround setup).</p>

      <p>The buffer processes <strong>once</strong>, but outputs to <strong>three channels</strong>.</p>
    </div>
  </div>

  <!-- Buffer Supply Expanded Details -->
  <section id="buffersupply-detail" class="tutorial-expanded">
    <h2>Expansion 1: What "Supply" Means</h2>

    <details>
      <summary>Click to expand: The Difference Between Registration and Supply</summary>

      <p><strong>Registration</strong> (<code>vega.AudioBuffer()[0] | Audio</code>):</p>

      <ul>
        <li>Adds buffer as a <strong>child</strong> of <code>RootAudioBuffer[0]</code></li>
        <li>Buffer processes during channel 0's cycle</li>
        <li>Output <strong>accumulates</strong> into channel 0</li>
      </ul>

      <p><strong>Supply</strong> (<code>supply_buffer_to_channels</code>):</p>

      <ul>
        <li>Adds buffer's <strong>output</strong> to other channels</li>
        <li>Buffer still processes in its original channel</li>
        <li>Output is <strong>copied</strong> to supplied channels</li>
      </ul>

      <p><strong>Analogy:</strong></p>

      <ul>
        <li>Registration = "This buffer lives in channel 0"</li>
        <li>Supply = "After processing in channel 0, send copies to channels 1 and 2"</li>
      </ul>

      <p><strong>Architecture:</strong></p>

      <pre><code>
Buffer processes in channel 0
    ↓
Output goes to RootAudioBuffer[0]
    ↓
MixProcessor copies output to RootAudioBuffer[1]
    ↓
MixProcessor copies output to RootAudioBuffer[2]
      </code></pre>

      <p><strong>Key:</strong> The buffer only processes <strong>once</strong>. Supply is a <strong>routing</strong> operation, not a duplication of processing.</p>
    </details>

    <h2>Expansion 2: Mix Levels</h2>

    <details>
      <summary>Click to expand: Controlling Supply Amplitude</summary>

      <p>The <code>mix</code> parameter controls how much of the buffer's output is sent:</p>

      <pre><code class="language-cpp">
MayaFlux::supply_buffer_to_channel(buffer, 1, 1.0);  // 100% (unity gain)
MayaFlux::supply_buffer_to_channel(buffer, 2, 0.5);  // 50% (half amplitude)
MayaFlux::supply_buffer_to_channel(buffer, 3, 0.1);  // 10% (quiet)
      </code></pre>

      <p><strong>Use case: Stereo width control</strong></p>

      <pre><code class="language-cpp">
auto mono_source = vega.Sine(440.0);
auto buffer = vega.NodeBuffer(0, 512, mono_source)[0] | Audio;

// Send to left (full) and right (half) for asymmetric stereo
MayaFlux::supply_buffer_to_channel(buffer, 0, 1.0);  // Left
MayaFlux::supply_buffer_to_channel(buffer, 1, 0.5);  // Right (quieter)
      </code></pre>

      <p><strong>Use case: Send effects</strong></p>

      <pre><code class="language-cpp">
auto dry = vega.NodeBuffer(0, 512, sine)[0] | Audio;  // Dry signal, channel 0

// Send 30% to reverb channel
MayaFlux::supply_buffer_to_channel(dry, 2, 0.3);  // Channel 2 = reverb bus
      </code></pre>

      <p>Mix is <strong>additive</strong>. If channel already has content, supply <strong>adds</strong> to it.</p>
    </details>

    <h2>Expansion 3: Removing Supply</h2>

    <details>
      <summary>Click to expand: Dynamic Routing Changes</summary>

      <p>You can remove supply relationships:</p>

      <pre><code class="language-cpp">
auto buffer = vega.NodeBuffer(0, 512, sine)[0] | Audio;
MayaFlux::supply_buffer_to_channel(buffer, 1);

// Later: stop sending to channel 1
MayaFlux::remove_supplied_buffer_from_channel(buffer, 1);

// Or remove from multiple channels at once
MayaFlux::remove_supplied_buffer_from_channels(buffer, {1, 2, 3});
      </code></pre>

      <p><strong>Use case: Mute individual sends</strong></p>

      <ul>
        <li>Buffer still processes</li>
        <li>Output still goes to its registered channel</li>
        <li>Supplied channels no longer receive it</li>
      </ul>

      <p><strong>Use case: Dynamic routing matrices</strong></p>

      <pre><code class="language-cpp">
if (user_pressed_button_A) {
    MayaFlux::supply_buffer_to_channel(buffer, 1);
} else {
    MayaFlux::remove_supplied_buffer_from_channel(buffer, 1);
}
      </code></pre>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Quad panning (4-channel surround)
auto source = vega.Sine(220.0);
auto buffer = vega.NodeBuffer(0, 512, source)[0] | Audio;

// Distribute to 4 corners with different levels (panning)
MayaFlux::supply_buffer_to_channel(buffer, 0, 0.7);  // Front-left
MayaFlux::supply_buffer_to_channel(buffer, 1, 0.3);  // Front-right
MayaFlux::supply_buffer_to_channel(buffer, 2, 0.2);  // Rear-left
MayaFlux::supply_buffer_to_channel(buffer, 3, 0.1);  // Rear-right

// Send effects architecture
auto guitar = vega.NodeBuffer(0, 512, source)[0] | Audio;  // Channel 0 = dry
auto reverb_bus = vega.FeedbackBuffer(1, 512, 0.7f, 4800)[1] | Audio;  // Channel 1 = reverb
auto delay_bus = vega.FeedbackBuffer(2, 512, 0.6f, 9600)[2] | Audio;   // Channel 2 = delay

MayaFlux::supply_buffer_to_channel(guitar, 1, 0.4);  // 40% to reverb
MayaFlux::supply_buffer_to_channel(guitar, 2, 0.2);  // 20% to delay

// Multi-band processing (split frequency ranges across channels)
// Process each band independently, then sum
    </code></pre>
  </section>

  <!-- =================== CHILD CARD 3: Buffer Cloning =================== -->

  <div class="tutorial-row">
    <div class="tutorial-card" data-target="buffercloning-detail">
      <h3 class="tutorial-title">Buffer Cloning</h3>
      <p class="hint">Click this card to reveal full explanation</p>

      <h4>The Pattern</h4>

      <p>One buffer specification, multiple independent instances.</p>

      <pre><code class="language-cpp">
void compose() {
    auto sine = vega.Sine(440.0);
    auto buffer = vega.NodeBuffer(0, 512, sine);  // Don't register yet

    // Clone to channels 0, 1, 2
    MayaFlux::clone_buffer_to_channels(buffer, {0, 1, 2});
}
      </code></pre>

      <p>Run this. You hear <strong>three independent sine waves</strong> on three channels.</p>

      <p>Each clone processes <strong>independently</strong>—they don't share data.</p>
    </div>
  </div>

  <!-- Buffer Cloning Expanded Details -->
  <section id="buffercloning-detail" class="tutorial-expanded">
    <h2>Expansion 1: Clone vs. Supply</h2>

    <details>
      <summary>Click to expand: When to Use Each</summary>

      <p><strong>Supply:</strong></p>

      <ul>
        <li>One buffer processes <strong>once</strong></li>
        <li>Output is <strong>copied</strong> to multiple channels</li>
        <li>Processing cost: <strong>1× processing</strong></li>
        <li>Memory: <strong>One buffer</strong></li>
        <li>Use when: Same signal needs to go to multiple places</li>
      </ul>

      <p><strong>Clone:</strong></p>

      <ul>
        <li>Multiple buffers process <strong>independently</strong></li>
        <li>Each has its own data, state, processing chain</li>
        <li>Processing cost: <strong>N× processing</strong> (N = number of clones)</li>
        <li>Memory: <strong>N buffers</strong></li>
        <li>Use when: Similar buffers need independent processing</li>
      </ul>

      <p><strong>Example: Supply use case</strong></p>

      <pre><code class="language-cpp">
// One reverb output to stereo speakers
auto reverb = vega.FeedbackBuffer(0, 512, 0.8f, 4800)[0] | Audio;
MayaFlux::supply_buffer_to_channel(reverb, 1);  // Copy to right channel
// Cost: 1× reverb processing
      </code></pre>

      <p><strong>Example: Clone use case</strong></p>

      <pre><code class="language-cpp">
// Independent noise generators per channel
auto noise_template = vega.NodeBuffer(0, 512, vega.Random(-1.0, 1.0));
MayaFlux::clone_buffer_to_channels(noise_template, {0, 1, 2, 3});
// Cost: 4× noise processing (each with different random seed/state)
// Result: Decorrelated noise on each channel
      </code></pre>
    </details>

    <h2>Expansion 2: Cloning Preserves Structure</h2>

    <details>
      <summary>Click to expand: What Gets Cloned</summary>

      <p>When you clone a buffer, each clone receives:</p>

      <ul>
        <li><strong>Same buffer type</strong> (NodeBuffer, FeedbackBuffer, etc.)</li>
        <li><strong>Same default processor</strong> configuration</li>
        <li><strong>Same processing chain</strong> (all added processors)</li>
        <li><strong>Independent data</strong> (not shared—each clone has its own samples)</li>
        <li><strong>Independent state</strong> (feedback buffers have separate history)</li>
      </ul>

      <p><strong>Example: Clone a processed buffer</strong></p>

      <pre><code class="language-cpp">
auto sine = vega.Sine(440.0);
auto buffer = vega.NodeBuffer(0, 512, sine);

// Add processing before cloning
auto distortion = vega.Polynomial([](double x) { return std::tanh(x * 2.0); });
MayaFlux::create_processor&lt;PolynomialProcessor&gt;(buffer, distortion);

// Now clone
MayaFlux::clone_buffer_to_channels(buffer, {0, 1, 2});

// Result: Each channel gets sine → distortion (independently processed)
      </code></pre>

      <p>Each clone has its own instance of the distortion processor. They don't share state.</p>
    </details>

    <h2>Expansion 3: Post-Clone Modification</h2>

    <details>
      <summary>Click to expand: Differentiating Clones After Creation</summary>

      <p>After cloning, you can modify individual clones:</p>

      <pre><code class="language-cpp">
auto buffer = vega.NodeBuffer(0, 512, vega.Sine(440.0));
// Store cloned buffers for later reference
auto cloned_buffers = MayaFlux::clone_buffer_to_channels(buffer, { 0, 1, 2 });


// Add different processing to each
std::vector&lt;double&gt; coeffs_a_2 = { 0.2, 0.3, 0.2 };
std::vector&lt;double&gt; coeffs_b_2 = { 1.0, -0.7 };
auto filter1 = vega.IIR(coeffs_a_1, coeffs_b_1);
auto filter2 = vega.IIR(coeffs_a_2, coeffs_b_2);

MayaFlux::create_processor&lt;FilterProcessor&gt;(cloned_buffers[0], filter1);
MayaFlux::create_processor&lt;FilterProcessor&gt;(cloned_buffers[1], filter2);

// Now channel 0 has one filter, channel 1 has a different filter
      </code></pre>

      <p><strong>Use case:</strong> Stereo decorrelation (same source, slightly different processing per channel)</p>
    </details>

    <hr />

    <h2>Try It</h2>

    <pre><code class="language-cpp">
// Stereo chorus (cloned with phase offset)
auto lfo = vega.Sine(0.5);  // Slow LFO
auto buffer = vega.NodeBuffer(0, 512, lfo);
MayaFlux::clone_buffer_to_channels(buffer, {0, 1});
// Modify one clone to have phase offset (requires accessing clone directly)

// Multi-channel granular synthesis
auto grain_template = vega.NodeBuffer(0, 512, vega.Random(-0.1, 0.1));
MayaFlux::clone_buffer_to_channels(grain_template, {0, 1, 2, 3, 4, 5, 6, 7});
// Each channel generates independent grains

// Independent feedback loops per channel
auto feedback_template = vega.FeedbackBuffer(0, 512, 0.8f, 1000);
MayaFlux::clone_buffer_to_channels(feedback_template, {0, 1, 2, 3});
// Excite each with different input → 4 independent resonances
    </code></pre>
  </section>

  <!-- =================== CLOSING SUMMARY =================== -->

  <hr />

  <h2>Closing: The Routing Ecosystem</h2>

  <p>You now understand:</p>

  <p><strong>Input Capture:</strong></p>

  <ul>
    <li><code>InputAudioBuffer</code>: Hardware input hub</li>
    <li><code>InputAccessProcessor</code>: Dispatches to listeners</li>
    <li><code>create_input_listener_buffer()</code>: Quick setup</li>
    <li><code>read_from_audio_input()</code> / <code>detach_from_audio_input()</code>: Manual control</li>
  </ul>

  <p><strong>Buffer Supply:</strong></p>

  <ul>
    <li><code>supply_buffer_to_channel()</code>: Route one buffer to multiple outputs</li>
    <li>Mix levels: Control send amounts</li>
    <li>Efficiency: Process once, output many times</li>
    <li><code>remove_supplied_buffer_from_channel()</code>: Dynamic routing changes</li>
  </ul>

  <p><strong>Buffer Cloning:</strong></p>

  <ul>
    <li><code>clone_buffer_to_channels()</code>: Create independent copies</li>
    <li>Preserves structure: Type, processors, chains</li>
    <li>Independent state: Each clone processes separately</li>
    <li>Post-clone modification: Differentiate behavior after creation</li>
  </ul>

  <p><strong>Mental Model:</strong></p>

  <pre><code>
Input (Microphone)
    ↓
InputAudioBuffer → Listener buffers (capture)
    ↓
Processing chains (transform)
    ↓
Supply (route to multiple channels)
    OR
Clone (create independent instances)
    ↓
RootAudioBuffer (mix per channel)
    ↓
Output (Speakers)
  </code></pre>

  <p><strong>Next:</strong> BufferPipeline (declarative multi-stage workflows with temporal control)</p>

    </div>
<!-- </section> -->
</section>
